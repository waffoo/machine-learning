{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Net  (MNIST)\n",
    "---\n",
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T07:59:21.451216Z",
     "start_time": "2018-05-12T07:58:44.231157Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T07:59:27.079951Z",
     "start_time": "2018-05-12T07:59:27.038959Z"
    }
   },
   "outputs": [],
   "source": [
    "N=10000 #reduce size of the dataset (70k)\n",
    "indices = np.random.permutation(range(len(mnist.data)))[:N]\n",
    "x = mnist.data[indices]\n",
    "t = mnist.target[indices]\n",
    "t = np.eye(10)[t.astype(int)]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-12T07:59:30.720486Z",
     "start_time": "2018-05-12T07:59:29.536635Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DNN:\n",
    "    def __init__(self, n_in, n_hids, n_out):\n",
    "        self.n_in, self.n_hids, self.n_out = n_in, n_hids, n_out\n",
    "        self.weights, self.biases = [], []\n",
    "        self._x, self_t = None, None\n",
    "        self._keep_prob = None\n",
    "        self._sess = None\n",
    "        self._history = {'accuracy':[], 'loss':[]}\n",
    "        self.Accuracy = None\n",
    "        \n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def inference(self, x, keep_prob):\n",
    "        for i, n_hid in enumerate(self.n_hids):\n",
    "            if i is 0:\n",
    "                input = x\n",
    "                input_dim = self.n_in\n",
    "            else:\n",
    "                input = output\n",
    "                input_dim = self.n_hids[i-1]\n",
    "                \n",
    "            self.weights.append(self.weight_variable([input_dim, n_hid]))\n",
    "            self.biases.append(self.bias_variable([n_hid]))\n",
    "            \n",
    "            h = tf.nn.relu(tf.matmul(input, self.weights[-1]) + self.biases[-1])\n",
    "            output = tf.nn.dropout(h, keep_prob)\n",
    "            \n",
    "        self.weights.append(self.weight_variable([self.n_hids[-1], self.n_out]))\n",
    "        self.biases.append(self.bias_variable([self.n_out]))\n",
    "        \n",
    "        return tf.nn.softmax(tf.matmul(output, self.weights[-1]) + self.biases[-1])\n",
    "    \n",
    "    def loss(self, y, t):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), axis=1))\n",
    "        return cross_entropy\n",
    "    \n",
    "    def training(self, loss):\n",
    "        return tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "    def accuracy(self, y, t):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "        return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    def fit(self, X_train, Y_train, epochs=100, batch_size=100, p_keep=0.5, verbose=1):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_in]) \n",
    "        t = tf.placeholder(tf.float32, shape=[None, self.n_out]) \n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self._x = x\n",
    "        self._t = t\n",
    "        self._keep_prob = keep_prob\n",
    "        \n",
    "        y = self.inference(x, keep_prob)\n",
    "        loss = self.loss(y, t)\n",
    "        train_step = self.training(loss)\n",
    "        self.Accuracy = self.accuracy(y, t)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        self._sess = sess\n",
    "        \n",
    "        N_train = len(X_train)\n",
    "        n_batches = N_train // batch_size\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            X_, Y_ = shuffle(X_train, Y_train)\n",
    "            \n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start +batch_size\n",
    "                sess.run(train_step, feed_dict={x:X_[start:end], t:Y_[start:end], keep_prob:p_keep})\n",
    "                loss_ = loss.eval(session=sess, feed_dict={x:X_train, t:Y_train, keep_prob:1.0})\n",
    "                accuracy_ = self.Accuracy.eval(session=sess, feed_dict={x:X_train, t:Y_train, keep_prob:1.0})\n",
    "                \n",
    "                self._history['loss'].append(loss_)\n",
    "                self._history['accuracy'].append(accuracy_)\n",
    "                \n",
    "            if verbose:\n",
    "                print('epoch:', epoch, 'loss', round(loss_, 3), 'accuracy:', round(accuracy_, 3))\n",
    "            \n",
    "        return self._history\n",
    "    \n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        return self.Accuracy.eval(session= self._sess, feed_dict={self._x:X_test, self._t:Y_test, self._keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-12T07:59:33.776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss 0.543 accuracy: 0.827\n",
      "epoch: 1 loss 0.441 accuracy: 0.852\n"
     ]
    }
   ],
   "source": [
    "model = DNN(n_in=784, n_hids=[200,200], n_out=10)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=200, p_keep=0.5)\n",
    "\n",
    "print('accuracy:', model.evaluate(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
